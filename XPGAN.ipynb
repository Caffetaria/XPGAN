{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XPGAN-github.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8122825d189046eb916787b8c35ab622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f822d7b54dca4c19a96500e605cd75bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1944d12a5774613a139624c242bcd62",
              "IPY_MODEL_0601662a6d614045a6d65e099d747145"
            ]
          }
        },
        "f822d7b54dca4c19a96500e605cd75bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1944d12a5774613a139624c242bcd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df0942496d514713917bddd534e0b611",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0a39dff130348979d5cf7fdb3758664"
          }
        },
        "0601662a6d614045a6d65e099d747145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f19129b78d842e0867221504f3690c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [23:32&lt;00:00, 407kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e61c084b2834c249ec53756fe7a095a"
          }
        },
        "df0942496d514713917bddd534e0b611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0a39dff130348979d5cf7fdb3758664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f19129b78d842e0867221504f3690c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e61c084b2834c249ec53756fe7a095a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNU2OV8f1qWf",
        "outputId": "e8e7d884-62dc-49c7-acb3-c948374fdbbd"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSJfdxGW4_IE"
      },
      "source": [
        "import pandas as pd\n",
        "import os, math, sys\n",
        "import glob, itertools\n",
        "import argparse, random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log10, sqrt\n",
        "from skimage import measure\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import vgg19\n",
        "from torchvision.models.vgg import vgg16\n",
        "from torchvision.models.vgg import vgg19\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "from tqdm.auto import tqdm\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "random.seed(42)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ymuDm3T5AhR"
      },
      "source": [
        "\n",
        "batch_size = 16\n",
        "lr = 0.0002\n",
        "b1 = 0.5\n",
        "b2 = 0.999\n",
        "n_cpu = 16\n",
        "hr_height = 256\n",
        "hr_width = 256\n",
        "channels = 3\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "hr_shape = (hr_height, hr_width)\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, files, hr_shape):\n",
        "        hr_height, hr_width = hr_shape\n",
        "        # Transforms for low resolution images and high resolution images\n",
        "        self.lr_transform = transforms.Compose(\n",
        "            [    \n",
        "                transforms.Resize((hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "             \n",
        "            ]\n",
        "        )\n",
        "        self.hr_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "        self.files = files\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index % len(self.files)]).convert(\"RGB\")\n",
        "        image = cv2.imread(self.files[index % len(self.files)]) \n",
        "        #Training with random filters\n",
        "        n = random. randint(1,40)\n",
        "        #Moving average filter\n",
        "        kernel = np.ones((n,n),np.float32)/(n ** 2)\n",
        "        dst = cv2.filter2D(image,-1,kernel)\n",
        "        dst = Image.fromarray(dst)\n",
        "        img_lr = self.lr_transform(dst)\n",
        "        img_hr = self.hr_transform(img)\n",
        "\n",
        "        return {\"lr\": img_lr, \"hr\": img_hr}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE64Wht95CIZ",
        "outputId": "b56182fd-e9f2-4000-c433-c06466dcd098"
      },
      "source": [
        "train_paths1 = sorted(glob.glob(\"/content/drive/My Drive/data/patches/train-resized/1\" + \"/*.*\"))\n",
        "print(len(train_paths1))\n",
        "train_paths2 = sorted(glob.glob(\"/content/drive/My Drive/data/patches/train-resized/2\" + \"/*.*\"))\n",
        "train_paths3 = sorted(glob.glob(\"/content/drive/My Drive/data/patches/train-resized/3\" + \"/*.*\"))\n",
        "train_paths4 = sorted(glob.glob(\"/content/drive/My Drive/data/patches/train-resized/4\" + \"/*.*\"))\n",
        "train_paths5 = sorted(glob.glob(\"/content/drive/My Drive/data/patches/train-resized/5\" + \"/*.*\"))\n",
        "train_paths6 = sorted(glob.glob(\"/content/drive/My Drive/data/patches/train-resized/6\" + \"/*.*\"))\n",
        "train_paths = train_paths1 + train_paths2 + train_paths3 + train_paths4 + train_paths5 + train_paths6 \n",
        "print(len(train_paths))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5887\n",
            "30884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEvtiT4P5DbT"
      },
      "source": [
        "test_paths = sorted(glob.glob(\"/content/drive/My Drive/data/patches/test-resized\" + \"/*.*\"))\n",
        "print(len(test_paths))\n",
        "train_dataloader = DataLoader(ImageDataset(train_paths, hr_shape=hr_shape), batch_size=16, shuffle=True, num_workers=n_cpu)\n",
        "test_dataloader = DataLoader(ImageDataset(test_paths, hr_shape=hr_shape), batch_size=1, shuffle=False, num_workers=n_cpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jZe9K9L5E1S"
      },
      "source": [
        "#Network structure follows from https://github.com/leftthomas/SRGAN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "        upsample_block_num = int(math.log(scale_factor, 2))\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.block4 = ResidualBlock(64)\n",
        "        self.block5 = ResidualBlock(64)\n",
        "        self.block6 = ResidualBlock(64)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        block8 = [UpsampleBLock(64, 2) for _ in range(upsample_block_num)]\n",
        "        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (torch.tanh(block8) + 1) / 2\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return torch.sigmoid(self.net(x).view(batch_size))\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super(UpsampleBLock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742,
          "referenced_widgets": [
            "8122825d189046eb916787b8c35ab622",
            "f822d7b54dca4c19a96500e605cd75bf",
            "b1944d12a5774613a139624c242bcd62",
            "0601662a6d614045a6d65e099d747145",
            "df0942496d514713917bddd534e0b611",
            "d0a39dff130348979d5cf7fdb3758664",
            "8f19129b78d842e0867221504f3690c2",
            "0e61c084b2834c249ec53756fe7a095a"
          ]
        },
        "id": "7ubi7MuO5GIS",
        "outputId": "526f1ac9-ad5d-4d1b-bb29-f28e45f564d3"
      },
      "source": [
        "\n",
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorLoss, self).__init__()\n",
        "        vgg = vgg19(pretrained=True)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for param in loss_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.loss_network = loss_network\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.tv_loss = TVLoss()\n",
        "        \n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        # Adversarial Loss\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        # Perception Loss - Vgg loss\n",
        "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
        "        # Image Loss - pixel-wise loss\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "        # TV Loss\n",
        "        tv_loss = self.tv_loss(out_images)\n",
        "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
        "\n",
        "\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, tv_loss_weight=1):\n",
        "        super(TVLoss, self).__init__()\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
        "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
        "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_size(t):\n",
        "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    g_loss = GeneratorLoss()\n",
        "    print(g_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8122825d189046eb916787b8c35ab622",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "GeneratorLoss(\n",
            "  (loss_network): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (mse_loss): MSELoss()\n",
            "  (tv_loss): TVLoss()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5drvTCu5O8f"
      },
      "source": [
        "generator = Generator(scale_factor=4)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "criterion_GAN = GeneratorLoss()\n",
        "if cuda:\n",
        "    generator = generator.cuda()\n",
        "    discriminator = discriminator.cuda()\n",
        "    criterion_GAN = criterion_GAN.cuda()\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "g_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lambda _: 0.1)\n",
        "d_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lambda _: 0.1)\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNTIWkNU5SLG"
      },
      "source": [
        "train_gen_losses, train_disc_losses, train_counter = [], [], []\n",
        "test_gen_losses, test_disc_losses = [], []\n",
        "test_counter = [idx*len(train_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    gen_loss, disc_loss = 0, 0\n",
        "    tqdm_bar = tqdm(train_dataloader, desc=f'Training Epoch {epoch} ', total=int(len(train_dataloader)))\n",
        "    if(epoch == 50):\n",
        "        g_scheduler.step()\n",
        "        d_scheduler.step()\n",
        "    for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "        generator.train(); discriminator.train()\n",
        "\n",
        "        imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
        "        imgs_hr = Variable(imgs[\"hr\"].type(Tensor))\n",
        "\n",
        "        valid = Variable(Tensor(np.ones((imgs_lr.size(0)))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((imgs_lr.size(0)))), requires_grad=False)\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "         \n",
        "        gen_hr = generator(imgs_lr)\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        real_out = discriminator(imgs_hr).mean()\n",
        "        fake_out = discriminator(gen_hr).mean()\n",
        "        loss_D = 1 - real_out + fake_out\n",
        "        loss_D.backward(retain_graph=True)\n",
        "        optimizer_D.step()\n",
        "        optimizer_G.zero_grad()\n",
        "        loss_G = criterion_GAN(discriminator(gen_hr).mean(), gen_hr, imgs_hr )\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "        \n",
        "        gen_loss += loss_G.item()\n",
        "        train_gen_losses.append(loss_G.item())\n",
        "        disc_loss += loss_D.item()\n",
        "        train_disc_losses.append(loss_D.item())\n",
        "        train_counter.append(batch_idx*batch_size + imgs_lr.size(0) + epoch*len(train_dataloader.dataset))\n",
        "        tqdm_bar.set_postfix(gen_loss=gen_loss/(batch_idx+1), disc_loss=disc_loss/(batch_idx+1))\n",
        "\n",
        "    gen_loss, disc_loss = 0, 0\n",
        "    tqdm_bar = tqdm(test_dataloader, desc=f'Testing Epoch {epoch} ', total=int(len(test_dataloader)))\n",
        "    index = 1\n",
        "    for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "        generator.eval(); discriminator.eval()\n",
        "        imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
        "        imgs_hr = Variable(imgs[\"hr\"].type(Tensor))\n",
        "        valid = Variable(Tensor(np.ones((imgs_lr.size(0)))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((imgs_lr.size(0)))), requires_grad=False)\n",
        "\n",
        "        gen_hr = generator(imgs_lr)\n",
        "\n",
        "        real_out = discriminator(imgs_hr).mean()\n",
        "        fake_out = discriminator(gen_hr).mean()\n",
        "        loss_D = 1 - real_out + fake_out\n",
        "        loss_G = criterion_GAN(discriminator(gen_hr).mean(), gen_hr, imgs_hr )\n",
        "        gen_loss += loss_G.item()\n",
        "        disc_loss += loss_D.item()\n",
        "        tqdm_bar.set_postfix(gen_loss=gen_loss/(batch_idx+1), disc_loss=disc_loss/(batch_idx+1))\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
        "            imgs_hr = make_grid(imgs_hr, nrow=1, normalize=True)\n",
        "            gen_hr = make_grid(gen_hr, nrow=1, normalize=True)\n",
        "            imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
        "            img_grid = torch.cat((imgs_hr, imgs_lr, gen_hr), -1)\n",
        "            save_image(img_grid, f\"/content/drive/My Drive/data/images/{epoch}_{batch_idx }.png\", normalize=False)\n",
        "\n",
        "    test_gen_losses.append(gen_loss/len(test_dataloader))\n",
        "    test_disc_losses.append(disc_loss/len(test_dataloader))\n",
        "\n",
        "    state = {\n",
        "    'epoch': epoch,\n",
        "    'gen_state_dict': generator.state_dict(),\n",
        "    'disc_state_dict': discriminator.state_dict(),\n",
        "    'g_optimizer': optimizer_G.state_dict(),\n",
        "    'd_optimizer': optimizer_D.state_dict(),\n",
        "    }\n",
        "    torch.save(state, f\"/content/drive/My Drive/data/graphs/state-after-{epoch}-epoch.pt\")\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjuJ9K9J7Qnv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}